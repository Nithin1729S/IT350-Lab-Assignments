{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b9a614-7bce-46f5-8aa0-bc95dfa0299d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 Results:\n",
      "Correctly Classified Instances: 14\n",
      "Incorrectly Classified Instances: 1\n",
      "Accuracy: 0.9333\n",
      "Root Mean Squared Error: 0.2582\n",
      "Relative Absolute Error: 0.0893\n",
      "True Positive Rate: 0.9167\n",
      "False Positive Rate: 0.0370\n",
      "Kappa Score: 0.8973\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5. 0. 0.]\n",
      " [0. 3. 1.]\n",
      " [0. 0. 6.]]\n",
      "\n",
      "Fold 2 Results:\n",
      "Correctly Classified Instances: 15\n",
      "Incorrectly Classified Instances: 0\n",
      "Accuracy: 1.0000\n",
      "Root Mean Squared Error: 0.0000\n",
      "Relative Absolute Error: 0.0000\n",
      "True Positive Rate: 1.0000\n",
      "False Positive Rate: 0.0000\n",
      "Kappa Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6. 0. 0.]\n",
      " [0. 5. 0.]\n",
      " [0. 0. 4.]]\n",
      "\n",
      "Fold 3 Results:\n",
      "Correctly Classified Instances: 15\n",
      "Incorrectly Classified Instances: 0\n",
      "Accuracy: 1.0000\n",
      "Root Mean Squared Error: 0.0000\n",
      "Relative Absolute Error: 0.0000\n",
      "True Positive Rate: 1.0000\n",
      "False Positive Rate: 0.0000\n",
      "Kappa Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2. 0. 0.]\n",
      " [0. 7. 0.]\n",
      " [0. 0. 6.]]\n",
      "\n",
      "Fold 4 Results:\n",
      "Correctly Classified Instances: 13\n",
      "Incorrectly Classified Instances: 2\n",
      "Accuracy: 0.8667\n",
      "Root Mean Squared Error: 0.3651\n",
      "Relative Absolute Error: 0.1923\n",
      "True Positive Rate: 0.8667\n",
      "False Positive Rate: 0.0741\n",
      "Kappa Score: 0.7945\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4. 0. 0.]\n",
      " [0. 3. 2.]\n",
      " [0. 0. 6.]]\n",
      "\n",
      "Fold 5 Results:\n",
      "Correctly Classified Instances: 15\n",
      "Incorrectly Classified Instances: 0\n",
      "Accuracy: 1.0000\n",
      "Root Mean Squared Error: 0.0000\n",
      "Relative Absolute Error: 0.0000\n",
      "True Positive Rate: 1.0000\n",
      "False Positive Rate: 0.0000\n",
      "Kappa Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3. 0. 0.]\n",
      " [0. 9. 0.]\n",
      " [0. 0. 3.]]\n",
      "\n",
      "Fold 6 Results:\n",
      "Correctly Classified Instances: 14\n",
      "Incorrectly Classified Instances: 1\n",
      "Accuracy: 0.9333\n",
      "Root Mean Squared Error: 0.2582\n",
      "Relative Absolute Error: 0.0833\n",
      "True Positive Rate: 0.9444\n",
      "False Positive Rate: 0.0278\n",
      "Kappa Score: 0.8980\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6. 0. 0.]\n",
      " [0. 3. 0.]\n",
      " [0. 1. 5.]]\n",
      "\n",
      "Fold 7 Results:\n",
      "Correctly Classified Instances: 15\n",
      "Incorrectly Classified Instances: 0\n",
      "Accuracy: 1.0000\n",
      "Root Mean Squared Error: 0.0000\n",
      "Relative Absolute Error: 0.0000\n",
      "True Positive Rate: 1.0000\n",
      "False Positive Rate: 0.0000\n",
      "Kappa Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5. 0. 0.]\n",
      " [0. 5. 0.]\n",
      " [0. 0. 5.]]\n",
      "\n",
      "Fold 8 Results:\n",
      "Correctly Classified Instances: 14\n",
      "Incorrectly Classified Instances: 1\n",
      "Accuracy: 0.9333\n",
      "Root Mean Squared Error: 0.2582\n",
      "Relative Absolute Error: 0.0974\n",
      "True Positive Rate: 0.9333\n",
      "False Positive Rate: 0.0278\n",
      "Kappa Score: 0.8958\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7. 0. 0.]\n",
      " [0. 4. 1.]\n",
      " [0. 0. 3.]]\n",
      "\n",
      "Fold 9 Results:\n",
      "Correctly Classified Instances: 13\n",
      "Incorrectly Classified Instances: 2\n",
      "Accuracy: 0.8667\n",
      "Root Mean Squared Error: 0.3651\n",
      "Relative Absolute Error: 0.2000\n",
      "True Positive Rate: 0.8667\n",
      "False Positive Rate: 0.0667\n",
      "Kappa Score: 0.8000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5. 0. 0.]\n",
      " [0. 5. 0.]\n",
      " [0. 2. 3.]]\n",
      "\n",
      "Fold 10 Results:\n",
      "Correctly Classified Instances: 14\n",
      "Incorrectly Classified Instances: 1\n",
      "Accuracy: 0.9333\n",
      "Root Mean Squared Error: 0.2582\n",
      "Relative Absolute Error: 0.0765\n",
      "True Positive Rate: 0.9444\n",
      "False Positive Rate: 0.0256\n",
      "Kappa Score: 0.8929\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 1. 5.]]\n",
      "\n",
      "Average Metrics Across All Folds:\n",
      "Average Accuracy: 0.9467\n",
      "Average RMSE: 0.1763\n",
      "Average RAE: 0.0739\n",
      "Average TPR: 0.9472\n",
      "Average FPR: 0.0259\n",
      "Average Kappa Score: 0.9178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.n_classes = len(self.classes)\n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "        # Calculate prior probabilities|\n",
    "        self.priors = np.zeros(self.n_classes)\n",
    "        for i, c in enumerate(self.classes):\n",
    "            self.priors[i] = np.mean(y == c)\n",
    "        \n",
    "        # Calculate mean and variance for each feature in each class\n",
    "        self.means = np.zeros((self.n_classes, self.n_features))\n",
    "        self.vars = np.zeros((self.n_classes, self.n_features))\n",
    "        \n",
    "        for i, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.means[i, :] = X_c.mean(axis=0)\n",
    "            self.vars[i, :] = X_c.var(axis=0)\n",
    "    \n",
    "    def _calculate_likelihood(self, x, mean, var):\n",
    "        eps = 1e-10  # To avoid division by zero\n",
    "        coef = 1.0 / np.sqrt(2.0 * np.pi * var + eps)\n",
    "        exponent = -0.5 * ((x - mean) ** 2) / (var + eps)\n",
    "        return coef * np.exp(exponent)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i, x in enumerate(X):\n",
    "            posteriors = []\n",
    "            \n",
    "            # Calculate posterior probability for each class\n",
    "            for c in range(self.n_classes):\n",
    "                prior = np.log(self.priors[c])\n",
    "                likelihood = np.sum(np.log(self._calculate_likelihood(x, self.means[c, :], self.vars[c, :])))\n",
    "                posterior = prior + likelihood\n",
    "                posteriors.append(posterior)\n",
    "            \n",
    "            # Select class with highest posterior probability\n",
    "            y_pred[i] = self.classes[np.argmax(posteriors)]\n",
    "            \n",
    "        return y_pred\n",
    "\n",
    "def k_fold_split(X, y, k=10):\n",
    "    fold_size = len(X) // k\n",
    "    X_folds = []\n",
    "    y_folds = []\n",
    "    \n",
    "    indices = np.random.permutation(len(X))\n",
    "    for i in range(k):\n",
    "        start_idx = i * fold_size\n",
    "        end_idx = start_idx + fold_size if i < k-1 else len(X)\n",
    "        \n",
    "        fold_indices = indices[start_idx:end_idx]\n",
    "        X_folds.append(X[fold_indices])\n",
    "        y_folds.append(y[fold_indices])\n",
    "    \n",
    "    return X_folds, y_folds\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, n_classes=3):\n",
    "    conf_matrix = np.zeros((n_classes, n_classes))\n",
    "    for i in range(len(y_true)):\n",
    "        conf_matrix[int(y_true[i])][int(y_pred[i])] += 1\n",
    "    \n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    incorrect = len(y_true) - correct\n",
    "    accuracy = correct / len(y_true)\n",
    "    \n",
    "    tpr = np.zeros(n_classes)\n",
    "    fpr = np.zeros(n_classes)\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        tp = conf_matrix[i][i]\n",
    "        fn = np.sum(conf_matrix[i]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fp - fn\n",
    "        \n",
    "        tpr[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fpr[i] = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    baseline_mae = np.mean(np.abs(y_true - np.mean(y_true)))\n",
    "    rae = mae / baseline_mae if baseline_mae != 0 else 0\n",
    "    \n",
    "    expected_accuracy = 0\n",
    "    for i in range(n_classes):\n",
    "        row_sum = np.sum(conf_matrix[i])\n",
    "        col_sum = np.sum(conf_matrix[:, i])\n",
    "        expected_accuracy += (row_sum * col_sum) / np.sum(conf_matrix)**2\n",
    "    \n",
    "    kappa = (accuracy - expected_accuracy) / (1 - expected_accuracy)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'correct': correct,\n",
    "        'incorrect': incorrect,\n",
    "        'rmse': rmse,\n",
    "        'rae': rae,\n",
    "        'tpr': np.mean(tpr),\n",
    "        'fpr': np.mean(fpr),\n",
    "        'kappa': kappa,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "k = 10\n",
    "X_folds, y_folds = k_fold_split(X, y, k)\n",
    "metrics_per_fold = []\n",
    "\n",
    "for fold in range(k):\n",
    "    X_test = X_folds[fold]\n",
    "    y_test = y_folds[fold]\n",
    "    \n",
    "    X_train = np.concatenate([X_folds[i] for i in range(k) if i != fold])\n",
    "    y_train = np.concatenate([y_folds[i] for i in range(k) if i != fold])\n",
    "    \n",
    "    nb = GaussianNaiveBayes()\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    \n",
    "    fold_metrics = calculate_metrics(y_test, y_pred)\n",
    "    metrics_per_fold.append(fold_metrics)\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} Results:\")\n",
    "    print(f\"Correctly Classified Instances: {fold_metrics['correct']}\")\n",
    "    print(f\"Incorrectly Classified Instances: {fold_metrics['incorrect']}\")\n",
    "    print(f\"Accuracy: {fold_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {fold_metrics['rmse']:.4f}\")\n",
    "    print(f\"Relative Absolute Error: {fold_metrics['rae']:.4f}\")\n",
    "    print(f\"True Positive Rate: {fold_metrics['tpr']:.4f}\")\n",
    "    print(f\"False Positive Rate: {fold_metrics['fpr']:.4f}\")\n",
    "    print(f\"Kappa Score: {fold_metrics['kappa']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(fold_metrics['confusion_matrix'])\n",
    "\n",
    "print(\"\\nAverage Metrics Across All Folds:\")\n",
    "avg_metrics = {\n",
    "    'accuracy': np.mean([m['accuracy'] for m in metrics_per_fold]),\n",
    "    'rmse': np.mean([m['rmse'] for m in metrics_per_fold]),\n",
    "    'rae': np.mean([m['rae'] for m in metrics_per_fold]),\n",
    "    'tpr': np.mean([m['tpr'] for m in metrics_per_fold]),\n",
    "    'fpr': np.mean([m['fpr'] for m in metrics_per_fold]),\n",
    "    'kappa': np.mean([m['kappa'] for m in metrics_per_fold])\n",
    "}\n",
    "\n",
    "print(f\"Average Accuracy: {avg_metrics['accuracy']:.4f}\")\n",
    "print(f\"Average RMSE: {avg_metrics['rmse']:.4f}\")\n",
    "print(f\"Average RAE: {avg_metrics['rae']:.4f}\")\n",
    "print(f\"Average TPR: {avg_metrics['tpr']:.4f}\")\n",
    "print(f\"Average FPR: {avg_metrics['fpr']:.4f}\")\n",
    "print(f\"Average Kappa Score: {avg_metrics['kappa']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe7a588-f070-4c04-90fa-1212021ba8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 Results:\n",
      "Correctly Classified Instances: 21\n",
      "Incorrectly Classified Instances: 5\n",
      "Accuracy: 0.8077\n",
      "Precision: 1.0000\n",
      "Recall: 0.7619\n",
      "F1 Score: 0.8649\n",
      "True Positive Rate: 0.7619\n",
      "False Positive Rate: 0.0000\n",
      "Kappa Score: 0.5517\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  0]\n",
      " [ 5  5]]\n",
      "\n",
      "Fold 2 Results:\n",
      "Correctly Classified Instances: 23\n",
      "Incorrectly Classified Instances: 3\n",
      "Accuracy: 0.8846\n",
      "Precision: 0.9500\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.9268\n",
      "True Positive Rate: 0.9048\n",
      "False Positive Rate: 0.2000\n",
      "Kappa Score: 0.6549\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  1]\n",
      " [ 2  4]]\n",
      "\n",
      "Fold 3 Results:\n",
      "Correctly Classified Instances: 20\n",
      "Incorrectly Classified Instances: 6\n",
      "Accuracy: 0.7692\n",
      "Precision: 0.9412\n",
      "Recall: 0.7619\n",
      "F1 Score: 0.8421\n",
      "True Positive Rate: 0.7619\n",
      "False Positive Rate: 0.2000\n",
      "Kappa Score: 0.4307\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  1]\n",
      " [ 5  4]]\n",
      "\n",
      "Fold 4 Results:\n",
      "Correctly Classified Instances: 19\n",
      "Incorrectly Classified Instances: 7\n",
      "Accuracy: 0.7308\n",
      "Precision: 0.8500\n",
      "Recall: 0.8095\n",
      "F1 Score: 0.8293\n",
      "True Positive Rate: 0.8095\n",
      "False Positive Rate: 0.6000\n",
      "Kappa Score: 0.1947\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  3]\n",
      " [ 4  2]]\n",
      "\n",
      "Fold 5 Results:\n",
      "Correctly Classified Instances: 19\n",
      "Incorrectly Classified Instances: 7\n",
      "Accuracy: 0.7308\n",
      "Precision: 0.9375\n",
      "Recall: 0.7143\n",
      "F1 Score: 0.8108\n",
      "True Positive Rate: 0.7143\n",
      "False Positive Rate: 0.2000\n",
      "Kappa Score: 0.3724\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  1]\n",
      " [ 6  4]]\n",
      "\n",
      "Fold 6 Results:\n",
      "Correctly Classified Instances: 19\n",
      "Incorrectly Classified Instances: 7\n",
      "Accuracy: 0.7308\n",
      "Precision: 0.9375\n",
      "Recall: 0.7143\n",
      "F1 Score: 0.8108\n",
      "True Positive Rate: 0.7143\n",
      "False Positive Rate: 0.2000\n",
      "Kappa Score: 0.3724\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  1]\n",
      " [ 6  4]]\n",
      "\n",
      "Fold 7 Results:\n",
      "Correctly Classified Instances: 22\n",
      "Incorrectly Classified Instances: 4\n",
      "Accuracy: 0.8462\n",
      "Precision: 0.9474\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.9000\n",
      "True Positive Rate: 0.8571\n",
      "False Positive Rate: 0.2000\n",
      "Kappa Score: 0.5702\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  1]\n",
      " [ 3  4]]\n",
      "\n",
      "Fold 8 Results:\n",
      "Correctly Classified Instances: 21\n",
      "Incorrectly Classified Instances: 5\n",
      "Accuracy: 0.8077\n",
      "Precision: 1.0000\n",
      "Recall: 0.7619\n",
      "F1 Score: 0.8649\n",
      "True Positive Rate: 0.7619\n",
      "False Positive Rate: 0.0000\n",
      "Kappa Score: 0.5517\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  0]\n",
      " [ 5  5]]\n",
      "\n",
      "Fold 9 Results:\n",
      "Correctly Classified Instances: 20\n",
      "Incorrectly Classified Instances: 6\n",
      "Accuracy: 0.7692\n",
      "Precision: 0.8571\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.8571\n",
      "True Positive Rate: 0.8571\n",
      "False Positive Rate: 0.6000\n",
      "Kappa Score: 0.2571\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  3]\n",
      " [ 3  2]]\n",
      "\n",
      "Fold 10 Results:\n",
      "Correctly Classified Instances: 28\n",
      "Incorrectly Classified Instances: 5\n",
      "Accuracy: 0.8485\n",
      "Precision: 0.9091\n",
      "Recall: 0.8696\n",
      "F1 Score: 0.8889\n",
      "True Positive Rate: 0.8696\n",
      "False Positive Rate: 0.2000\n",
      "Kappa Score: 0.6512\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20  2]\n",
      " [ 3  8]]\n",
      "\n",
      "Average Metrics Across All Folds:\n",
      "Average Accuracy: 0.7925\n",
      "Average Precision: 0.9330\n",
      "Average Recall: 0.8012\n",
      "Average F1 Score: 0.8596\n",
      "Average TPR: 0.8012\n",
      "Average FPR: 0.2400\n",
      "Average Kappa Score: 0.4607\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch SPECT Heart dataset\n",
    "spect_heart = fetch_ucirepo(id=95)\n",
    "X = spect_heart.data.features.to_numpy()\n",
    "y = spect_heart.data.targets.to_numpy().ravel()\n",
    "\n",
    "class BernoulliNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the Bernoulli Naive Bayes classifier\n",
    "        Specifically adapted for binary features in SPECT dataset\n",
    "        \"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        self.n_classes = len(self.classes)\n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "        # Calculate prior probabilities\n",
    "        self.class_priors = {}\n",
    "        for c in self.classes:\n",
    "            self.class_priors[c] = np.mean(y == c)\n",
    "        \n",
    "        # Calculate feature probabilities for each class\n",
    "        self.feature_probs = {}\n",
    "        for c in self.classes:\n",
    "            # Get samples for this class\n",
    "            X_c = X[y == c]\n",
    "            \n",
    "            # Calculate probability of feature being 1 in this class\n",
    "            # Add smoothing to avoid zero probabilities\n",
    "            alpha = 1.0  # Laplace smoothing parameter\n",
    "            feature_counts = np.sum(X_c == 1, axis=0) + alpha\n",
    "            total_samples = len(X_c) + 2 * alpha\n",
    "            self.feature_probs[c] = feature_counts / total_samples\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples in X\n",
    "        Using log probabilities for numerical stability\n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i, x in enumerate(X):\n",
    "            # Calculate log probability for each class\n",
    "            log_probs = {}\n",
    "            for c in self.classes:\n",
    "                # Start with log prior\n",
    "                log_prob = np.log(self.class_priors[c])\n",
    "                \n",
    "                # Add log likelihood for each feature\n",
    "                for j, x_j in enumerate(x):\n",
    "                    if x_j == 1:\n",
    "                        log_prob += np.log(self.feature_probs[c][j])\n",
    "                    else:\n",
    "                        log_prob += np.log(1 - self.feature_probs[c][j])\n",
    "                \n",
    "                log_probs[c] = log_prob\n",
    "            \n",
    "            # Select class with highest probability\n",
    "            y_pred[i] = max(log_probs.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "# Keep the same k_fold_split and calculate_metrics functions\n",
    "\n",
    "# Perform k-fold cross validation with stratification\n",
    "k = 10\n",
    "# Stratify the folds to maintain class distribution\n",
    "unique_classes = np.unique(y)\n",
    "class_indices = {c: np.where(y == c)[0] for c in unique_classes}\n",
    "\n",
    "# Create stratified folds\n",
    "X_folds = []\n",
    "y_folds = []\n",
    "for c in unique_classes:\n",
    "    indices = class_indices[c]\n",
    "    np.random.shuffle(indices)\n",
    "    fold_size = len(indices) // k\n",
    "    for i in range(k):\n",
    "        if i == 0:\n",
    "            if len(X_folds) < k:\n",
    "                X_folds.extend([[] for _ in range(k)])\n",
    "                y_folds.extend([[] for _ in range(k)])\n",
    "        start_idx = i * fold_size\n",
    "        end_idx = start_idx + fold_size if i < k-1 else len(indices)\n",
    "        fold_indices = indices[start_idx:end_idx]\n",
    "        X_folds[i].extend(X[fold_indices])\n",
    "        y_folds[i].extend(y[fold_indices])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_folds = [np.array(fold) for fold in X_folds]\n",
    "y_folds = [np.array(fold) for fold in y_folds]\n",
    "\n",
    "metrics_per_fold = []\n",
    "\n",
    "for fold in range(k):\n",
    "    # Prepare training and testing data\n",
    "    X_test = X_folds[fold]\n",
    "    y_test = y_folds[fold]\n",
    "    \n",
    "    X_train = np.vstack([X_folds[i] for i in range(k) if i != fold])\n",
    "    y_train = np.concatenate([y_folds[i] for i in range(k) if i != fold])\n",
    "    \n",
    "    # Train and predict\n",
    "    nb = BernoulliNaiveBayes()\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    fold_metrics = calculate_metrics(y_test, y_pred)\n",
    "    metrics_per_fold.append(fold_metrics)\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} Results:\")\n",
    "    print(f\"Correctly Classified Instances: {fold_metrics['correct']}\")\n",
    "    print(f\"Incorrectly Classified Instances: {fold_metrics['incorrect']}\")\n",
    "    print(f\"Accuracy: {fold_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {fold_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {fold_metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {fold_metrics['f1_score']:.4f}\")\n",
    "    print(f\"True Positive Rate: {fold_metrics['tpr']:.4f}\")\n",
    "    print(f\"False Positive Rate: {fold_metrics['fpr']:.4f}\")\n",
    "    print(f\"Kappa Score: {fold_metrics['kappa']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(fold_metrics['confusion_matrix'])\n",
    "\n",
    "# Calculate and print average metrics across all folds\n",
    "print(\"\\nAverage Metrics Across All Folds:\")\n",
    "avg_metrics = {\n",
    "    'accuracy': np.mean([m['accuracy'] for m in metrics_per_fold]),\n",
    "    'precision': np.mean([m['precision'] for m in metrics_per_fold]),\n",
    "    'recall': np.mean([m['recall'] for m in metrics_per_fold]),\n",
    "    'f1_score': np.mean([m['f1_score'] for m in metrics_per_fold]),\n",
    "    'tpr': np.mean([m['tpr'] for m in metrics_per_fold]),\n",
    "    'fpr': np.mean([m['fpr'] for m in metrics_per_fold]),\n",
    "    'kappa': np.mean([m['kappa'] for m in metrics_per_fold])\n",
    "}\n",
    "\n",
    "print(f\"Average Accuracy: {avg_metrics['accuracy']:.4f}\")\n",
    "print(f\"Average Precision: {avg_metrics['precision']:.4f}\")\n",
    "print(f\"Average Recall: {avg_metrics['recall']:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_metrics['f1_score']:.4f}\")\n",
    "print(f\"Average TPR: {avg_metrics['tpr']:.4f}\")\n",
    "print(f\"Average FPR: {avg_metrics['fpr']:.4f}\")\n",
    "print(f\"Average Kappa Score: {avg_metrics['kappa']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e56a6f-ea6e-4eff-8d71-6056d6a8f5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
